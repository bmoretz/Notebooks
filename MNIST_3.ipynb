{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bmoretz/Notebooks/blob/master/MNIST_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "hwcwWKVfpPt_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import time\n",
        "from datetime import timedelta\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lDW9qfGepQZq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Convolutional layer 1# Convolutional Layer 1.\n",
        "filter_size1 = 5          # Convolution filters (kernel) are 5 x 5 pixels.\n",
        "num_filters1 = 16         # There are 16 of these filters. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QJ3c48YfpRjm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Convolutional Layer 2.\n",
        "filter_size2 = 5          # Convolution filters are 5 x 5 pixels.\n",
        "num_filters2 = 32         # There are 32 of these filters.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vo5QLrowpSbz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Fully-connected layer.\n",
        "fc_size = 128             # Number of neurons in fully-connected layer."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Sgo4SJwxpTeG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "5644074e-9092-4472-f3b5-545fabd159a1"
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "data = input_data.read_data_sets('data/MNIST/', one_hot=True)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/train-images-idx3-ubyte.gz\n",
            "Extracting data/MNIST/train-labels-idx1-ubyte.gz\n",
            "Extracting data/MNIST/t10k-images-idx3-ubyte.gz\n",
            "Extracting data/MNIST/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2gRl06sHpUXq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "pkeep = tf.placeholder(tf.float32)\n",
        "data.test.cls = np.argmax(data.test.labels, axis=1)\n",
        "\n",
        "# We know that MNIST images are 28 pixels in each dimension.\n",
        "img_size = 28\n",
        "\n",
        "# Images are stored in one-dimensional arrays of this length.\n",
        "img_size_flat = img_size * img_size\n",
        "\n",
        "# Tuple with height and width of images used to reshape arrays.\n",
        "img_shape = (img_size, img_size)\n",
        "\n",
        "# Number of colour channels for the images: 1 channel for gray-scale.\n",
        "num_channels = 1\n",
        "\n",
        "# Number of classes, one class for each of 10 digits.\n",
        "num_classes = 10\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "95GTpxVEpVRw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def plot_images(images, cls_true, cls_pred=None):\n",
        "    assert len(images) == len(cls_true) == 9\n",
        "    \n",
        "    # Create figure with 3x3 sub-plots.\n",
        "    fig, axes = plt.subplots(3, 3)\n",
        "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
        "\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        # Plot image.\n",
        "        ax.imshow(images[i].reshape(img_shape), cmap='binary')\n",
        "\n",
        "        # Show true and predicted classes.\n",
        "        if cls_pred is None:\n",
        "            xlabel = \"True: {0}\".format(cls_true[i])\n",
        "        else:\n",
        "            xlabel = \"True: {0}, Pred: {1}\".format(cls_true[i], cls_pred[i])\n",
        "\n",
        "        # Show the classes as the label on the x-axis.\n",
        "        ax.set_xlabel(xlabel)\n",
        "        \n",
        "        # Remove ticks from the plot.\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "    \n",
        "    # Ensure the plot is shown correctly with multiple plots\n",
        "    # in a single Notebook cell.\n",
        "    plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dAIWg8L3pWPM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "outputId": "7c822776-4415-433b-c187-18d77d67d5cd"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Get the first images from the test-set.\n",
        "images = data.test.images[0:9]\n",
        "\n",
        "# Get the true classes for those images.\n",
        "cls_true = data.test.cls[0:9]\n",
        "\n",
        "# Plot the images and labels using our helper-function above.\n",
        "plot_images(images=images, cls_true=cls_true)\n",
        "\n",
        "\n",
        "def new_weights(shape):\n",
        "    return tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
        "\n",
        "\n",
        "def new_biases(length):\n",
        "    return tf.Variable(tf.constant(0.05, shape=[length]))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaMAAAFHCAYAAAAMQCNgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f97b543da20>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "UjEcpVV7pXgA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def new_conv_layer(input,              # The previous layer.\n",
        "                   num_input_channels, # Num. channels in prev. layer.\n",
        "                   filter_size,        # Width and height of each filter.\n",
        "                   num_filters,        # Number of filters.\n",
        "                   use_pooling=True):  # Use 2x2 max-pooling.\n",
        "\n",
        "    # Shape of the filter-weights for the convolution.\n",
        "    # This format is determined by the TensorFlow API.\n",
        "    shape = [filter_size, filter_size, num_input_channels, num_filters]\n",
        "\n",
        "    # Create new weights aka. filters with the given shape.\n",
        "    weights = new_weights(shape=shape)\n",
        "\n",
        "    # Create new biases, one for each filter.\n",
        "    biases = new_biases(length=num_filters)\n",
        "\n",
        "    # Create the TensorFlow operation for convolution.\n",
        "    # Note the strides are set to 1 in all dimensions.\n",
        "    # The first and last stride must always be 1,\n",
        "    # because the first is for the image-number and\n",
        "    # the last is for the input-channel.\n",
        "    # But e.g. strides=[1, 2, 2, 1] would mean that the filter\n",
        "    # is moved 2 pixels across the x- and y-axis of the image.\n",
        "    # The padding is set to 'SAME' which means the input image\n",
        "    # is padded with zeroes so the size of the output is the same.\n",
        "    layer = tf.nn.conv2d(input=input,\n",
        "                         filter=weights,\n",
        "                         strides=[1, 1, 1, 1],\n",
        "                         padding='SAME')\n",
        "\n",
        "    # Add the biases to the results of the convolution.\n",
        "    # A bias-value is added to each filter-channel.\n",
        "    layer += biases\n",
        "\n",
        "    # Use pooling to down-sample the image resolution?\n",
        "    if use_pooling:\n",
        "        # This is 2x2 max-pooling, which means that we\n",
        "        # consider 2x2 windows and select the largest value\n",
        "        # in each window. Then we move 2 pixels to the next window.\n",
        "        layer = tf.nn.max_pool(value=layer,\n",
        "                               ksize=[1, 2, 2, 1],\n",
        "                               strides=[1, 2, 2, 1],\n",
        "                               padding='SAME')\n",
        "\n",
        "    # Rectified Linear Unit (ReLU).\n",
        "    # It calculates max(x, 0) for each input pixel x.\n",
        "    # This adds some non-linearity to the formula and allows us\n",
        "    # to learn more complicated functions.\n",
        "    layer = tf.nn.relu(layer)\n",
        "    #layer_dp=tf.nn.dropout(layer, pkeep)\n",
        "\n",
        "    # Note that ReLU is normally executed before the pooling,\n",
        "    # but since relu(max_pool(x)) == max_pool(relu(x)) we can\n",
        "    # save 75% of the relu-operations by max-pooling first.\n",
        "\n",
        "    # We return both the resulting layer and the filter-weights\n",
        "    # because we will plot the weights later.\n",
        "    return layer, weights\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h73EjcWgpZRS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def flatten_layer(layer):\n",
        "    # Get the shape of the input layer.\n",
        "    layer_shape = layer.get_shape()\n",
        "\n",
        "    # The shape of the input layer is assumed to be:\n",
        "    # layer_shape == [num_images, img_height, img_width, num_channels]\n",
        "\n",
        "    # The number of features is: img_height * img_width * num_channels\n",
        "    # We can use a function from TensorFlow to calculate this.\n",
        "    num_features = layer_shape[1:4].num_elements()\n",
        "    \n",
        "    # Reshape the layer to [num_images, num_features].\n",
        "    # Note that we just set the size of the second dimension\n",
        "    # to num_features and the size of the first dimension to -1\n",
        "    # which means the size in that dimension is calculated\n",
        "    # so the total size of the tensor is unchanged from the reshaping.\n",
        "    layer_flat = tf.reshape(layer, [-1, num_features])\n",
        "\n",
        "    # The shape of the flattened layer is now:\n",
        "    # [num_images, img_height * img_width * num_channels]\n",
        "\n",
        "    # Return both the flattened layer and the number of features.\n",
        "    return layer_flat, num_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hme60WC5paf2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def new_fc_layer(input,          # The previous layer.\n",
        "                 num_inputs,     # Num. inputs from prev. layer.\n",
        "                 num_outputs,    # Num. outputs.\n",
        "                 use_relu=True): # Use Rectified Linear Unit (ReLU)?\n",
        "\n",
        "    # Create new weights and biases.\n",
        "    weights = new_weights(shape=[num_inputs, num_outputs])\n",
        "    biases = new_biases(length=num_outputs)\n",
        "\n",
        "    # Calculate the layer as the matrix multiplication of\n",
        "    # the input and weights, and then add the bias-values.\n",
        "    layer = tf.matmul(input, weights) + biases\n",
        "\n",
        "    # Use ReLU?\n",
        "    if use_relu:\n",
        "        layer = tf.nn.relu(layer)\n",
        "\n",
        "    return layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jQT4pfZepf5D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = tf.placeholder(tf.float32, shape=[None, img_size_flat], name='x')\n",
        "\n",
        "\n",
        "x_image = tf.reshape(x, [-1, img_size, img_size, num_channels])\n",
        "\n",
        "\n",
        "y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true')\n",
        "\n",
        "\n",
        "y_true_cls = tf.argmax(y_true, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hnQbPRE1qJzu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "layer_conv1, weights_conv1 = new_conv_layer(input=x_image,\n",
        "                   num_input_channels=num_channels,\n",
        "                   filter_size=filter_size1,\n",
        "                   num_filters=num_filters1,\n",
        "                   use_pooling=True)\n",
        "\n",
        "\n",
        "layer_conv2, weights_conv2 = new_conv_layer(input=layer_conv1,\n",
        "                   num_input_channels=num_filters1,\n",
        "                   filter_size=filter_size2,\n",
        "                   num_filters=num_filters2,\n",
        "                   use_pooling=True)\n",
        "\n",
        "layer_flat, num_features = flatten_layer(layer_conv2)\n",
        "\n",
        "\n",
        "layer_fc1 = new_fc_layer(input=layer_flat,\n",
        "                         num_inputs=num_features,\n",
        "                         num_outputs=fc_size,\n",
        "                         use_relu=True)\n",
        "\n",
        "\n",
        "\n",
        "layer_fc2 = new_fc_layer(input=layer_fc1,\n",
        "                         num_inputs=fc_size,\n",
        "                         num_outputs=num_classes,\n",
        "                         use_relu=False)\n",
        "\n",
        "\n",
        "\n",
        "y_pred = tf.nn.softmax(layer_fc2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ajx1Sg_SqLFy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "c6927d20-02e9-4b1b-a98b-226ed42d3d23"
      },
      "cell_type": "code",
      "source": [
        "y_pred_cls  = tf.argmax(y_pred, axis=1)\n",
        "\n",
        "\n",
        "#lr = 0.0001 +  tf.train.exponential_decay(0.003, step, 2000, 1/math.e)\n",
        "#train_step = tf.train.AdamOptimizer(lr).minimize(cross_entropy)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=layer_fc2,\n",
        "                                                        labels=y_true)\n",
        "\n",
        "\n",
        "cost = tf.reduce_mean(cross_entropy)\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-26-ad71bad9a982>:12: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uH0xuLFKqMvV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)\n",
        "#optimizer = tf.train.AdamOptimizer(lr).minimize(cost)\n",
        "\n",
        "correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
        "\n",
        "\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "\n",
        "session = tf.Session()\n",
        "\n",
        "session.run(tf.global_variables_initializer())\n",
        "\n",
        "\n",
        "train_batch_size = 64\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QrDzdAFLqN9W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Counter for total number of iterations performed so far.\n",
        "total_iterations = 0\n",
        "\n",
        "def optimize(num_iterations):\n",
        "    # Ensure we update the global variable rather than a local copy.\n",
        "    global total_iterations\n",
        "\n",
        "    # Start-time used for printing time-usage below.\n",
        "    start_time = time.time()\n",
        "\n",
        "    for i in range(total_iterations,\n",
        "                   total_iterations + num_iterations):\n",
        "\n",
        "        # Get a batch of training examples.\n",
        "        # x_batch now holds a batch of images and\n",
        "        # y_true_batch are the true labels for those images.\n",
        "        x_batch, y_true_batch = data.train.next_batch(train_batch_size)\n",
        "\n",
        "        # Put the batch into a dict with the proper names\n",
        "        # for placeholder variables in the TensorFlow graph.\n",
        "        feed_dict_train = {x: x_batch,\n",
        "                           y_true: y_true_batch}\n",
        "\n",
        "        # Run the optimizer using this batch of training data.\n",
        "        # TensorFlow assigns the variables in feed_dict_train\n",
        "        # to the placeholder variables and then runs the optimizer.\n",
        "        session.run(optimizer, feed_dict=feed_dict_train)\n",
        "\n",
        "        # Print status every 100 iterations.\n",
        "        if i % 100 == 0:\n",
        "            # Calculate the accuracy on the training-set.\n",
        "            acc = session.run(accuracy, feed_dict=feed_dict_train)\n",
        "\n",
        "            # Message for printing.\n",
        "            msg = \"Optimization Iteration: {0:>6}, Training Accuracy: {1:>6.1%}\"\n",
        "\n",
        "            # Print it.\n",
        "            print(msg.format(i + 1, acc))\n",
        "\n",
        "    # Update the total number of iterations performed.\n",
        "    total_iterations += num_iterations\n",
        "\n",
        "    # Ending time.\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Difference between start and end-times.\n",
        "    time_dif = end_time - start_time\n",
        "\n",
        "    # Print the time-usage.\n",
        "    print(\"Time usage: \" + str(timedelta(seconds=int(round(time_dif)))))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YG7XsL2iqPgN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def plot_example_errors(cls_pred, correct):\n",
        "    # This function is called from print_test_accuracy() below.\n",
        "\n",
        "    # cls_pred is an array of the predicted class-number for\n",
        "    # all images in the test-set.\n",
        "\n",
        "    # correct is a boolean array whether the predicted class\n",
        "    # is equal to the true class for each image in the test-set.\n",
        "\n",
        "    # Negate the boolean array.\n",
        "    incorrect = (correct == False)\n",
        "    \n",
        "    # Get the images from the test-set that have been\n",
        "    # incorrectly classified.\n",
        "    images = data.test.images[incorrect]\n",
        "    \n",
        "    # Get the predicted classes for those images.\n",
        "    cls_pred = cls_pred[incorrect]\n",
        "\n",
        "    # Get the true classes for those images.\n",
        "    cls_true = data.test.cls[incorrect]\n",
        "    \n",
        "    # Plot the first 9 images.\n",
        "    plot_images(images=images[0:9],\n",
        "                cls_true=cls_true[0:9],\n",
        "                cls_pred=cls_pred[0:9])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NBfec_TgqRC0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(cls_pred):\n",
        "    # This is called from print_test_accuracy() below.\n",
        "\n",
        "    # cls_pred is an array of the predicted class-number for\n",
        "    # all images in the test-set.\n",
        "\n",
        "    # Get the true classifications for the test-set.\n",
        "    cls_true = data.test.cls\n",
        "    \n",
        "    # Get the confusion matrix using sklearn.\n",
        "    cm = confusion_matrix(y_true=cls_true,\n",
        "                          y_pred=cls_pred)\n",
        "\n",
        "    # Print the confusion matrix as text.\n",
        "    print(cm)\n",
        "\n",
        "    # Plot the confusion matrix as an image.\n",
        "    plt.matshow(cm)\n",
        "\n",
        "    # Make various adjustments to the plot.\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(num_classes)\n",
        "    plt.xticks(tick_marks, range(num_classes))\n",
        "    plt.yticks(tick_marks, range(num_classes))\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "\n",
        "    # Ensure the plot is shown correctly with multiple plots\n",
        "    # in a single Notebook cell.\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dlGUwkzjqSiI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "test_batch_size = 256\n",
        "\n",
        "def print_test_accuracy(show_example_errors=False,\n",
        "                        show_confusion_matrix=False):\n",
        "\n",
        "    # Number of images in the test-set.\n",
        "    num_test = len(data.test.images)\n",
        "\n",
        "    # Allocate an array for the predicted classes which\n",
        "    # will be calculated in batches and filled into this array.\n",
        "    cls_pred = np.zeros(shape=num_test, dtype=np.int)\n",
        "\n",
        "    # Now calculate the predicted classes for the batches.\n",
        "    # We will just iterate through all the batches.\n",
        "    # There might be a more clever and Pythonic way of doing this.\n",
        "\n",
        "    # The starting index for the next batch is denoted i.\n",
        "    i = 0\n",
        "\n",
        "    while i < num_test:\n",
        "        # The ending index for the next batch is denoted j.\n",
        "        j = min(i + test_batch_size, num_test)\n",
        "\n",
        "        # Get the images from the test-set between index i and j.\n",
        "        images = data.test.images[i:j, :]\n",
        "\n",
        "        # Get the associated labels.\n",
        "        labels = data.test.labels[i:j, :]\n",
        "\n",
        "        # Create a feed-dict with these images and labels.\n",
        "        feed_dict = {x: images,\n",
        "                     y_true: labels}\n",
        "\n",
        "        # Calculate the predicted class using TensorFlow.\n",
        "        cls_pred[i:j] = session.run(y_pred_cls, feed_dict=feed_dict)\n",
        "\n",
        "        # Set the start-index for the next batch to the\n",
        "        # end-index of the current batch.\n",
        "        i = j\n",
        "\n",
        "    # Convenience variable for the true class-numbers of the test-set.\n",
        "    cls_true = data.test.cls\n",
        "\n",
        "    # Create a boolean array whether each image is correctly classified.\n",
        "    correct = (cls_true == cls_pred)\n",
        "\n",
        "    # Calculate the number of correctly classified images.\n",
        "    # When summing a boolean array, False means 0 and True means 1.\n",
        "    correct_sum = correct.sum()\n",
        "\n",
        "    # Classification accuracy is the number of correctly classified\n",
        "    # images divided by the total number of images in the test-set.\n",
        "    acc = float(correct_sum) / num_test\n",
        "\n",
        "    # Print the accuracy.\n",
        "    msg = \"Accuracy on Test-Set: {0:.1%} ({1} / {2})\"\n",
        "    print(msg.format(acc, correct_sum, num_test))\n",
        "\n",
        "    # Plot some examples of mis-classifications, if desired.\n",
        "    if show_example_errors:\n",
        "        print(\"Example errors:\")\n",
        "        plot_example_errors(cls_pred=cls_pred, correct=correct)\n",
        "\n",
        "    # Plot the confusion matrix, if desired.\n",
        "    if show_confusion_matrix:\n",
        "        print(\"Confusion Matrix:\")\n",
        "        plot_confusion_matrix(cls_pred=cls_pred)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_-qVnZ_HqUd8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "ad4f82ad-ded2-4451-8430-633f36353f66"
      },
      "cell_type": "code",
      "source": [
        "print_test_accuracy()\n",
        "\n",
        "optimize(num_iterations=1)\n",
        "print_test_accuracy()\n",
        "\n",
        "optimize(num_iterations=50)\n",
        "\n",
        "print_test_accuracy()\n",
        "\n",
        "\n",
        "optimize(num_iterations=99)\n",
        "\n",
        "print_test_accuracy()\n",
        "\n",
        "\n",
        "optimize(num_iterations=100)\n",
        "\n",
        "print_test_accuracy()\n",
        "\n",
        "\n",
        "optimize(num_iterations=1000)\n",
        "\n",
        "print_test_accuracy()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on Test-Set: 12.3% (1230 / 10000)\n",
            "Optimization Iteration:      1, Training Accuracy:  17.2%\n",
            "Time usage: 0:00:00\n",
            "Accuracy on Test-Set: 12.3% (1231 / 10000)\n",
            "Time usage: 0:00:04\n",
            "Accuracy on Test-Set: 38.6% (3862 / 10000)\n",
            "Optimization Iteration:    101, Training Accuracy:  62.5%\n",
            "Time usage: 0:00:08\n",
            "Accuracy on Test-Set: 68.8% (6875 / 10000)\n",
            "Optimization Iteration:    201, Training Accuracy:  81.2%\n",
            "Time usage: 0:00:08\n",
            "Accuracy on Test-Set: 83.9% (8389 / 10000)\n",
            "Optimization Iteration:    301, Training Accuracy:  92.2%\n",
            "Optimization Iteration:    401, Training Accuracy:  89.1%\n",
            "Optimization Iteration:    501, Training Accuracy:  85.9%\n",
            "Optimization Iteration:    601, Training Accuracy:  95.3%\n",
            "Optimization Iteration:    701, Training Accuracy:  85.9%\n",
            "Optimization Iteration:    801, Training Accuracy:  92.2%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8DQoh4moqVnq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "optimize(num_iterations=1000)\n",
        "\n",
        "print_test_accuracy(show_example_errors=True)\n",
        "\n",
        "\n",
        "optimize(num_iterations=9000)\n",
        "\n",
        "print_test_accuracy(show_example_errors=True,\n",
        "                    show_confusion_matrix=True)\n",
        "\n",
        "def plot_conv_weights(weights, input_channel=0):\n",
        "    # Assume weights are TensorFlow ops for 4-dim variables\n",
        "    # e.g. weights_conv1 or weights_conv2.\n",
        "    \n",
        "    # Retrieve the values of the weight-variables from TensorFlow.\n",
        "    # A feed-dict is not necessary because nothing is calculated.\n",
        "    w = session.run(weights)\n",
        "\n",
        "    # Get the lowest and highest values for the weights.\n",
        "    # This is used to correct the colour intensity across\n",
        "    # the images so they can be compared with each other.\n",
        "    w_min = np.min(w)\n",
        "    w_max = np.max(w)\n",
        "\n",
        "    # Number of filters used in the conv. layer.\n",
        "    num_filters = w.shape[3]\n",
        "\n",
        "    # Number of grids to plot.\n",
        "    # Rounded-up, square-root of the number of filters.\n",
        "    num_grids = math.ceil(math.sqrt(num_filters))\n",
        "    \n",
        "    # Create figure with a grid of sub-plots.\n",
        "    fig, axes = plt.subplots(num_grids, num_grids)\n",
        "\n",
        "    # Plot all the filter-weights.\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        # Only plot the valid filter-weights.\n",
        "        if i<num_filters:\n",
        "            # Get the weights for the i'th filter of the input channel.\n",
        "            # See new_conv_layer() for details on the format\n",
        "            # of this 4-dim tensor.\n",
        "            img = w[:, :, input_channel, i]\n",
        "\n",
        "            # Plot image.\n",
        "            ax.imshow(img, vmin=w_min, vmax=w_max,\n",
        "                      interpolation='nearest', cmap='seismic')\n",
        "        \n",
        "        # Remove ticks from the plot.\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "    \n",
        "    # Ensure the plot is shown correctly with multiple plots\n",
        "    # in a single Notebook cell.\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZCXEkVgkqX2X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def plot_conv_layer(layer, image):\n",
        "    # Assume layer is a TensorFlow op that outputs a 4-dim tensor\n",
        "    # which is the output of a convolutional layer,\n",
        "    # e.g. layer_conv1 or layer_conv2.\n",
        "\n",
        "    # Create a feed-dict containing just one image.\n",
        "    # Note that we don't need to feed y_true because it is\n",
        "    # not used in this calculation.\n",
        "    feed_dict = {x: [image]}\n",
        "\n",
        "    # Calculate and retrieve the output values of the layer\n",
        "    # when inputting that image.\n",
        "    values = session.run(layer, feed_dict=feed_dict)\n",
        "\n",
        "    # Number of filters used in the conv. layer.\n",
        "    num_filters = values.shape[3]\n",
        "\n",
        "    # Number of grids to plot.\n",
        "    # Rounded-up, square-root of the number of filters.\n",
        "    num_grids = math.ceil(math.sqrt(num_filters))\n",
        "    \n",
        "    # Create figure with a grid of sub-plots.\n",
        "    fig, axes = plt.subplots(num_grids, num_grids)\n",
        "\n",
        "    # Plot the output images of all the filters.\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        # Only plot the images for valid filters.\n",
        "        if i<num_filters:\n",
        "            # Get the output image of using the i'th filter.\n",
        "            # See new_conv_layer() for details on the format\n",
        "            # of this 4-dim tensor.\n",
        "            img = values[0, :, :, i]\n",
        "\n",
        "            # Plot image.\n",
        "            ax.imshow(img, interpolation='nearest', cmap='binary')\n",
        "        \n",
        "        # Remove ticks from the plot.\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "    \n",
        "    # Ensure the plot is shown correctly with multiple plots\n",
        "    # in a single Notebook cell.\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nt-R_O-XqZn0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_image(image):\n",
        "    plt.imshow(image.reshape(img_shape),\n",
        "               interpolation='nearest',\n",
        "               cmap='binary')\n",
        "\n",
        "    plt.show()   \n",
        "    \n",
        "image1 = data.test.images[0]\n",
        "plot_image(image1)    \n",
        "\n",
        "\n",
        "image2 = data.test.images[13]\n",
        "plot_image(image2)\n",
        "\n",
        "plot_conv_weights(weights=weights_conv1)\n",
        "\n",
        "\n",
        "plot_conv_layer(layer=layer_conv1, image=image1)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6H_QZHEXqaqw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}